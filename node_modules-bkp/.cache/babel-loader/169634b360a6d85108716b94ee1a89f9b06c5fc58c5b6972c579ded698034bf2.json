{"ast":null,"code":"'use strict';\n\nvar __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n    desc = {\n      enumerable: true,\n      get: function () {\n        return m[k];\n      }\n    };\n  }\n  Object.defineProperty(o, k2, desc);\n} : function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\nvar __setModuleDefault = this && this.__setModuleDefault || (Object.create ? function (o, v) {\n  Object.defineProperty(o, \"default\", {\n    enumerable: true,\n    value: v\n  });\n} : function (o, v) {\n  o[\"default\"] = v;\n});\nvar __importStar = this && this.__importStar || function (mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n  const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'),\n    crlfSearchRegex = /\\r?\\n|\\r/,\n    customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null,\n    expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays,\n    deeksOptions = {\n      arrayIndexesAsKeys: options.arrayIndexesAsKeys,\n      expandNestedObjects: options.expandNestedObjects,\n      expandArrayObjects: expandingWithoutUnwinding,\n      ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n      escapeNestedDots: true\n    };\n  /** HEADER FIELD FUNCTIONS **/\n  /**\n   * Returns the list of data field names of all documents in the provided list\n   */\n  function getFieldNameList(data) {\n    // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n    return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n  }\n  /**\n   * Processes the schemas by checking for schema differences, if so desired.\n   * If schema differences are not to be checked, then it resolves the unique\n   * list of field names.\n   */\n  function processSchemas(documentSchemas) {\n    // If there are no document schemas then there is nothing to diff and no unqiue fields to get\n    if (documentSchemas.length === 0) {\n      return [];\n    }\n    // If the user wants to check for the same schema (regardless of schema ordering)\n    if (options.checkSchemaDifferences) {\n      return checkSchemaDifferences(documentSchemas);\n    } else {\n      // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n      const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n      return uniqueFieldNames;\n    }\n  }\n  /**\n   * This function performs the schema difference check, if the user specifies that it should be checked.\n   * If there are no field names, then there are no differences.\n   * Otherwise, we get the first schema and the remaining list of schemas\n   */\n  function checkSchemaDifferences(documentSchemas) {\n    // have multiple documents - ensure only one schema (regardless of field ordering)\n    const firstDocSchema = documentSchemas[0],\n      restOfDocumentSchemas = documentSchemas.slice(1),\n      schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n    // If there are schema inconsistencies, throw a schema not the same error\n    if (schemaDifferences) {\n      throw new Error(constants_1.errors.json2csv.notSameSchema);\n    }\n    return firstDocSchema;\n  }\n  /**\n   * Computes the number of schema differences\n   */\n  function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n    return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n      // If there is a difference between the schemas, increment the counter of schema inconsistencies\n      const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n      return numberOfDifferences > 0 ? schemaDifferences + 1 : schemaDifferences;\n    }, 0);\n  }\n  /**\n   * If so specified, this filters the detected key paths to exclude any keys that have been specified\n   */\n  function filterExcludedKeys(keyPaths) {\n    if (options.excludeKeys) {\n      return keyPaths.filter(keyPath => {\n        for (const excludedKey of options.excludeKeys) {\n          // Only match if the excludedKey appears at the beginning of the string so we don't accidentally match a key farther down in a key path\n          const regex = excludedKey instanceof RegExp ? excludedKey : new RegExp(`^${excludedKey}`);\n          if (excludedKey === keyPath || keyPath.match(regex)) {\n            return false; // Exclude the key\n          }\n        }\n        return true; // Otherwise, include the key\n      });\n    }\n    return keyPaths;\n  }\n  /**\n   * If so specified, this sorts the header field names alphabetically\n   */\n  function sortHeaderFields(fieldNames) {\n    if (options.sortHeader && typeof options.sortHeader === 'function') {\n      return fieldNames.sort(options.sortHeader);\n    } else if (options.sortHeader) {\n      return fieldNames.sort();\n    }\n    return fieldNames;\n  }\n  /**\n   * Trims the header fields, if the user desires them to be trimmed.\n   */\n  function trimHeaderFields(params) {\n    if (options.trimHeaderFields) {\n      params.headerFields = params.headerFields.map(field => field.split('.').map(component => component.trim()).join('.'));\n    }\n    return params;\n  }\n  /**\n   * Wrap the headings, if desired by the user.\n   */\n  function wrapHeaderFields(params) {\n    // only perform this if we are actually prepending the header\n    if (options.prependHeader) {\n      params.headerFields = params.headerFields.map(function (headingKey) {\n        return wrapFieldValueIfNecessary(headingKey);\n      });\n    }\n    return params;\n  }\n  /**\n   * Generates the CSV header string by joining the headerFields by the field delimiter\n   */\n  function generateCsvHeader(params) {\n    // #185 - generate a keys list to avoid finding native Map() methods\n    const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n    params.header = params.headerFields.map(function (field) {\n      let headerKey = field;\n      // If a custom field title was provided for this field, use that\n      if (fieldTitleMapKeys.includes(field)) {\n        headerKey = options.fieldTitleMap[field];\n      } else if (!options.escapeHeaderNestedDots) {\n        // Otherwise, if the user doesn't want nested dots in keys to be escaped, then unescape them\n        headerKey = headerKey.replace(/\\\\\\./g, '.');\n      }\n      return headerKey;\n    }).join(options.delimiter.field);\n    return params;\n  }\n  function convertKeysToHeaderFields() {\n    if (!options.keys) return [];\n    return options.keys.map(key => {\n      if (typeof key === 'object' && 'field' in key) {\n        options.fieldTitleMap[key.field] = key.title ?? key.field;\n        return key.field;\n      }\n      return key;\n    });\n  }\n  function extractWildcardMatchKeys() {\n    if (!options.keys) return [];\n    return options.keys.flatMap(item => {\n      if (typeof item === 'string') {\n        // Exclude plain strings that were passed in options.keys\n        return [];\n      } else if (item?.wildcardMatch) {\n        // Return \"field\" value for objects with wildcardMatch: true\n        return item.field;\n      }\n      // Exclude other objects\n      return [];\n    });\n  }\n  /**\n   * Retrieve the headings for all documents and return it.\n   * This checks that all documents have the same schema.\n   */\n  function retrieveHeaderFields(data) {\n    const wildcardMatchKeys = extractWildcardMatchKeys();\n    const keyStrings = convertKeysToHeaderFields();\n    const fieldNames = getFieldNameList(data);\n    const processed = processSchemas(fieldNames);\n    if (options.keys) {\n      options.keys = keyStrings;\n      const matchedKeys = keyStrings.flatMap(userProvidedKey => {\n        // If this is not a wildcard matched key, then just return and include it in the resulting key list\n        if (!wildcardMatchKeys.includes(userProvidedKey)) {\n          return userProvidedKey;\n        }\n        // Otherwise, identify all detected keys that match with the provided wildcard key:\n        const matches = [];\n        const regex = new RegExp(`^${userProvidedKey}`);\n        for (const detectedKey of processed) {\n          if (userProvidedKey === detectedKey || detectedKey.match(regex)) {\n            matches.push(detectedKey);\n          }\n        }\n        return matches;\n      });\n      if (!options.unwindArrays) {\n        const filtered = filterExcludedKeys(matchedKeys);\n        return sortHeaderFields(filtered);\n      }\n    }\n    const filtered = filterExcludedKeys(processed);\n    return sortHeaderFields(filtered);\n  }\n  /** RECORD FIELD FUNCTIONS **/\n  /**\n   * Unwinds objects in arrays within record objects if the user specifies the\n   * expandArrayObjects option. If not specified, this passes the params\n   * argument through to the next function in the promise chain.\n   *\n   * The `finalPass` parameter is used to trigger one last pass to ensure no more\n   * arrays need to be expanded\n   */\n  function unwindRecordsIfNecessary(params, finalPass = false) {\n    if (options.unwindArrays) {\n      const originalRecordsLength = params.records.length;\n      // Unwind each of the documents at the given headerField\n      params.headerFields.forEach(headerField => {\n        params.records = utils.unwind(params.records, headerField);\n      });\n      const headerFields = retrieveHeaderFields(params.records);\n      params.headerFields = headerFields;\n      // If we were able to unwind more arrays, then try unwinding again...\n      if (originalRecordsLength !== params.records.length) {\n        return unwindRecordsIfNecessary(params);\n      }\n      // Otherwise, we didn't unwind any additional arrays, so continue...\n      // Run a final time in case the earlier unwinding exposed additional\n      // arrays to unwind...\n      if (!finalPass) {\n        return unwindRecordsIfNecessary(params, true);\n      }\n      // If keys were provided, set the headerFields back to the provided keys after unwinding:\n      if (options.keys) {\n        const userSelectedFields = convertKeysToHeaderFields();\n        params.headerFields = filterExcludedKeys(userSelectedFields);\n      }\n      return params;\n    }\n    return params;\n  }\n  /**\n   * Main function which handles the processing of a record, or document to be converted to CSV format\n   * This function specifies and performs the necessary operations in the necessary order\n   * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n   * * Order of operations:\n   * - Get fields from provided key list (as array of actual values)\n   * - Convert the values to csv/string representation [possible option here for custom converters?]\n   * - Trim fields\n   * - Determine if they need to be wrapped (& wrap if necessary)\n   * - Combine values for each line (by joining by field delimiter)\n   */\n  function processRecords(params) {\n    params.recordString = params.records.map(record => {\n      // Retrieve data for each of the headerFields from this record\n      const recordFieldData = retrieveRecordFieldData(record, params.headerFields),\n        // Process the data in this record and return the\n        processedRecordData = recordFieldData.map(fieldValue => {\n          fieldValue = trimRecordFieldValue(fieldValue);\n          fieldValue = preventCsvInjection(fieldValue);\n          let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n          stringified = wrapFieldValueIfNecessary(stringified);\n          return stringified;\n        });\n      // Join the record data by the field delimiter\n      return generateCsvRowFromRecord(processedRecordData);\n    }).join(options.delimiter.eol);\n    return params;\n  }\n  /**\n   * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n   */\n  function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n    const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n    // If we have an array and it's either empty of full of empty values, then use an empty value representation\n    if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n      return options.emptyFieldValue || '';\n    } else if (filteredRecordFieldValue.length === 1) {\n      // Otherwise, we have an array of actual values...\n      // Since we are expanding array objects, we will want to key in on values of objects.\n      return filteredRecordFieldValue[0]; // Extract the single value in the array\n    }\n    return recordFieldValue;\n  }\n  /**\n   * Gets all field values from a particular record for the given list of fields\n   */\n  function retrieveRecordFieldData(record, fields) {\n    const recordValues = [];\n    fields.forEach(field => {\n      let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n      if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n        recordFieldValue = options.emptyFieldValue;\n      } else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n        recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n      }\n      recordValues.push(recordFieldValue);\n    });\n    return recordValues;\n  }\n  /**\n   * Converts a record field value to its string representation\n   */\n  function recordFieldValueToString(fieldValue) {\n    const isDate = fieldValue instanceof Date; // store to avoid checking twice\n    if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n      return JSON.stringify(fieldValue);\n    } else if (typeof fieldValue === 'undefined') {\n      return 'undefined';\n    } else if (isDate && options.useDateIso8601Format) {\n      return fieldValue.toISOString();\n    } else {\n      return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n    }\n  }\n  /**\n   * Trims the record field value, if specified by the user's provided options\n   */\n  function trimRecordFieldValue(fieldValue) {\n    if (options.trimFieldValues) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(trimRecordFieldValue);\n      } else if (typeof fieldValue === 'string') {\n        return fieldValue.trim();\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Prevent CSV injection on strings if specified by the user's provided options.\n   * Mitigation will be done by ensuring that the first character doesn't being with:\n   * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n   * More info: https://owasp.org/www-community/attacks/CSV_Injection\n   */\n  function preventCsvInjection(fieldValue) {\n    if (options.preventCsvInjection) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(preventCsvInjection);\n      } else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n        return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Escapes quotation marks in the field value, if necessary, and appropriately\n   * wraps the record field value if it contains a comma (field delimiter),\n   * quotation mark (wrap delimiter), or a line break (CRLF)\n   */\n  function wrapFieldValueIfNecessary(fieldValue) {\n    const wrapDelimiter = options.delimiter.wrap;\n    // eg. includes quotation marks (default delimiter)\n    if (fieldValue.includes(options.delimiter.wrap)) {\n      // add an additional quotation mark before each quotation mark appearing in the field value\n      fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n    }\n    // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n    //   then enclose it in quotation marks (wrap delimiter)\n    if (fieldValue.includes(options.delimiter.field) || fieldValue.includes(options.delimiter.wrap) || fieldValue.match(crlfSearchRegex) || options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n      // wrap the field's value in a wrap delimiter (quotation marks by default)\n      fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n    }\n    return fieldValue;\n  }\n  /**\n   * Generates the CSV record string by joining the field values together by the field delimiter\n   */\n  function generateCsvRowFromRecord(recordFieldValues) {\n    return recordFieldValues.join(options.delimiter.field);\n  }\n  /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n  /**\n   * Performs the final CSV construction by combining the fields in the appropriate\n   * order depending on the provided options values and sends the generated CSV\n   * back to the user\n   */\n  function generateCsvFromComponents(params) {\n    const header = params.header,\n      records = params.recordString,\n      // If we are prepending the header, then add an EOL, otherwise just return the records\n      csv = (options.excelBOM ? constants_1.excelBOM : '') + (options.prependHeader ? header + options.delimiter.eol : '') + records;\n    return csv;\n  }\n  /** MAIN CONVERTER FUNCTION **/\n  /**\n   * Internally exported json2csv function\n   */\n  function convert(data) {\n    // Single document, not an array\n    if (!Array.isArray(data)) {\n      data = [data]; // Convert to an array of the given document\n    }\n    // Retrieve the heading and then generate the CSV with the keys that are identified\n    const headerFields = {\n      headerFields: retrieveHeaderFields(data),\n      records: data,\n      header: '',\n      recordString: ''\n    };\n    const unwinded = unwindRecordsIfNecessary(headerFields);\n    const processed = processRecords(unwinded);\n    const wrapped = wrapHeaderFields(processed);\n    const trimmed = trimHeaderFields(wrapped);\n    const generated = generateCsvHeader(trimmed);\n    return generateCsvFromComponents(generated);\n  }\n  return {\n    convert\n  };\n};\nexports.Json2Csv = Json2Csv;","map":{"version":3,"names":["__createBinding","Object","create","o","m","k","k2","undefined","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","get","defineProperty","__setModuleDefault","v","value","__importStar","mod","result","prototype","hasOwnProperty","call","exports","Json2Csv","doc_path_1","require","deeks_1","constants_1","utils","options","wrapDelimiterCheckRegex","RegExp","delimiter","wrap","crlfSearchRegex","customValueParser","parseValue","expandingWithoutUnwinding","expandArrayObjects","unwindArrays","deeksOptions","arrayIndexesAsKeys","expandNestedObjects","ignoreEmptyArraysWhenExpanding","escapeNestedDots","getFieldNameList","data","deepKeysFromList","processSchemas","documentSchemas","length","checkSchemaDifferences","uniqueFieldNames","unique","flatten","firstDocSchema","restOfDocumentSchemas","slice","schemaDifferences","computeNumberOfSchemaDifferences","Error","errors","json2csv","notSameSchema","reduce","documentSchema","numberOfDifferences","computeSchemaDifferences","filterExcludedKeys","keyPaths","excludeKeys","filter","keyPath","excludedKey","regex","match","sortHeaderFields","fieldNames","sortHeader","sort","trimHeaderFields","params","headerFields","map","field","split","component","trim","join","wrapHeaderFields","prependHeader","headingKey","wrapFieldValueIfNecessary","generateCsvHeader","fieldTitleMapKeys","keys","fieldTitleMap","header","headerKey","includes","escapeHeaderNestedDots","replace","convertKeysToHeaderFields","key","title","extractWildcardMatchKeys","flatMap","item","wildcardMatch","retrieveHeaderFields","wildcardMatchKeys","keyStrings","processed","matchedKeys","userProvidedKey","matches","detectedKey","push","filtered","unwindRecordsIfNecessary","finalPass","originalRecordsLength","records","forEach","headerField","unwind","userSelectedFields","processRecords","recordString","record","recordFieldData","retrieveRecordFieldData","processedRecordData","fieldValue","trimRecordFieldValue","preventCsvInjection","stringified","recordFieldValueToString","generateCsvRowFromRecord","eol","processRecordFieldDataForExpandedArrayObject","recordFieldValue","filteredRecordFieldValue","removeEmptyFields","emptyFieldValue","fields","recordValues","evaluatePath","isUndefined","isEmptyField","Array","isArray","isDate","Date","JSON","stringify","useDateIso8601Format","toISOString","useLocaleFormat","toString","toLocaleString","trimFieldValues","isNumber","wrapDelimiter","wrapBooleans","recordFieldValues","generateCsvFromComponents","csv","excelBOM","convert","unwinded","wrapped","trimmed","generated"],"sources":["/home/bipul/dashboard-dave/dynamodb-display/node_modules/json-2-csv/lib/json2csv.js"],"sourcesContent":["'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n    const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'), crlfSearchRegex = /\\r?\\n|\\r/, customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null, expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays, deeksOptions = {\n        arrayIndexesAsKeys: options.arrayIndexesAsKeys,\n        expandNestedObjects: options.expandNestedObjects,\n        expandArrayObjects: expandingWithoutUnwinding,\n        ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n        escapeNestedDots: true,\n    };\n    /** HEADER FIELD FUNCTIONS **/\n    /**\n     * Returns the list of data field names of all documents in the provided list\n     */\n    function getFieldNameList(data) {\n        // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n        return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n    }\n    /**\n     * Processes the schemas by checking for schema differences, if so desired.\n     * If schema differences are not to be checked, then it resolves the unique\n     * list of field names.\n     */\n    function processSchemas(documentSchemas) {\n        // If there are no document schemas then there is nothing to diff and no unqiue fields to get\n        if (documentSchemas.length === 0) {\n            return [];\n        }\n        // If the user wants to check for the same schema (regardless of schema ordering)\n        if (options.checkSchemaDifferences) {\n            return checkSchemaDifferences(documentSchemas);\n        }\n        else {\n            // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n            const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n            return uniqueFieldNames;\n        }\n    }\n    /**\n     * This function performs the schema difference check, if the user specifies that it should be checked.\n     * If there are no field names, then there are no differences.\n     * Otherwise, we get the first schema and the remaining list of schemas\n     */\n    function checkSchemaDifferences(documentSchemas) {\n        // have multiple documents - ensure only one schema (regardless of field ordering)\n        const firstDocSchema = documentSchemas[0], restOfDocumentSchemas = documentSchemas.slice(1), schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n        // If there are schema inconsistencies, throw a schema not the same error\n        if (schemaDifferences) {\n            throw new Error(constants_1.errors.json2csv.notSameSchema);\n        }\n        return firstDocSchema;\n    }\n    /**\n     * Computes the number of schema differences\n     */\n    function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n        return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n            // If there is a difference between the schemas, increment the counter of schema inconsistencies\n            const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n            return numberOfDifferences > 0\n                ? schemaDifferences + 1\n                : schemaDifferences;\n        }, 0);\n    }\n    /**\n     * If so specified, this filters the detected key paths to exclude any keys that have been specified\n     */\n    function filterExcludedKeys(keyPaths) {\n        if (options.excludeKeys) {\n            return keyPaths.filter((keyPath) => {\n                for (const excludedKey of options.excludeKeys) {\n                    // Only match if the excludedKey appears at the beginning of the string so we don't accidentally match a key farther down in a key path\n                    const regex = excludedKey instanceof RegExp ? excludedKey : new RegExp(`^${excludedKey}`);\n                    if (excludedKey === keyPath || keyPath.match(regex)) {\n                        return false; // Exclude the key\n                    }\n                }\n                return true; // Otherwise, include the key\n            });\n        }\n        return keyPaths;\n    }\n    /**\n     * If so specified, this sorts the header field names alphabetically\n     */\n    function sortHeaderFields(fieldNames) {\n        if (options.sortHeader && typeof options.sortHeader === 'function') {\n            return fieldNames.sort(options.sortHeader);\n        }\n        else if (options.sortHeader) {\n            return fieldNames.sort();\n        }\n        return fieldNames;\n    }\n    /**\n     * Trims the header fields, if the user desires them to be trimmed.\n     */\n    function trimHeaderFields(params) {\n        if (options.trimHeaderFields) {\n            params.headerFields = params.headerFields.map((field) => field.split('.')\n                .map((component) => component.trim())\n                .join('.'));\n        }\n        return params;\n    }\n    /**\n     * Wrap the headings, if desired by the user.\n     */\n    function wrapHeaderFields(params) {\n        // only perform this if we are actually prepending the header\n        if (options.prependHeader) {\n            params.headerFields = params.headerFields.map(function (headingKey) {\n                return wrapFieldValueIfNecessary(headingKey);\n            });\n        }\n        return params;\n    }\n    /**\n     * Generates the CSV header string by joining the headerFields by the field delimiter\n     */\n    function generateCsvHeader(params) {\n        // #185 - generate a keys list to avoid finding native Map() methods\n        const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n        params.header = params.headerFields\n            .map(function (field) {\n            let headerKey = field;\n            // If a custom field title was provided for this field, use that\n            if (fieldTitleMapKeys.includes(field)) {\n                headerKey = options.fieldTitleMap[field];\n            }\n            else if (!options.escapeHeaderNestedDots) {\n                // Otherwise, if the user doesn't want nested dots in keys to be escaped, then unescape them\n                headerKey = headerKey.replace(/\\\\\\./g, '.');\n            }\n            return headerKey;\n        })\n            .join(options.delimiter.field);\n        return params;\n    }\n    function convertKeysToHeaderFields() {\n        if (!options.keys)\n            return [];\n        return options.keys.map((key) => {\n            if (typeof key === 'object' && 'field' in key) {\n                options.fieldTitleMap[key.field] = key.title ?? key.field;\n                return key.field;\n            }\n            return key;\n        });\n    }\n    function extractWildcardMatchKeys() {\n        if (!options.keys)\n            return [];\n        return options.keys.flatMap(item => {\n            if (typeof item === 'string') {\n                // Exclude plain strings that were passed in options.keys\n                return [];\n            }\n            else if (item?.wildcardMatch) {\n                // Return \"field\" value for objects with wildcardMatch: true\n                return item.field;\n            }\n            // Exclude other objects\n            return [];\n        });\n    }\n    /**\n     * Retrieve the headings for all documents and return it.\n     * This checks that all documents have the same schema.\n     */\n    function retrieveHeaderFields(data) {\n        const wildcardMatchKeys = extractWildcardMatchKeys();\n        const keyStrings = convertKeysToHeaderFields();\n        const fieldNames = getFieldNameList(data);\n        const processed = processSchemas(fieldNames);\n        if (options.keys) {\n            options.keys = keyStrings;\n            const matchedKeys = keyStrings.flatMap((userProvidedKey) => {\n                // If this is not a wildcard matched key, then just return and include it in the resulting key list\n                if (!wildcardMatchKeys.includes(userProvidedKey)) {\n                    return userProvidedKey;\n                }\n                // Otherwise, identify all detected keys that match with the provided wildcard key:\n                const matches = [];\n                const regex = new RegExp(`^${userProvidedKey}`);\n                for (const detectedKey of processed) {\n                    if (userProvidedKey === detectedKey || detectedKey.match(regex)) {\n                        matches.push(detectedKey);\n                    }\n                }\n                return matches;\n            });\n            if (!options.unwindArrays) {\n                const filtered = filterExcludedKeys(matchedKeys);\n                return sortHeaderFields(filtered);\n            }\n        }\n        const filtered = filterExcludedKeys(processed);\n        return sortHeaderFields(filtered);\n    }\n    /** RECORD FIELD FUNCTIONS **/\n    /**\n     * Unwinds objects in arrays within record objects if the user specifies the\n     * expandArrayObjects option. If not specified, this passes the params\n     * argument through to the next function in the promise chain.\n     *\n     * The `finalPass` parameter is used to trigger one last pass to ensure no more\n     * arrays need to be expanded\n     */\n    function unwindRecordsIfNecessary(params, finalPass = false) {\n        if (options.unwindArrays) {\n            const originalRecordsLength = params.records.length;\n            // Unwind each of the documents at the given headerField\n            params.headerFields.forEach((headerField) => {\n                params.records = utils.unwind(params.records, headerField);\n            });\n            const headerFields = retrieveHeaderFields(params.records);\n            params.headerFields = headerFields;\n            // If we were able to unwind more arrays, then try unwinding again...\n            if (originalRecordsLength !== params.records.length) {\n                return unwindRecordsIfNecessary(params);\n            }\n            // Otherwise, we didn't unwind any additional arrays, so continue...\n            // Run a final time in case the earlier unwinding exposed additional\n            // arrays to unwind...\n            if (!finalPass) {\n                return unwindRecordsIfNecessary(params, true);\n            }\n            // If keys were provided, set the headerFields back to the provided keys after unwinding:\n            if (options.keys) {\n                const userSelectedFields = convertKeysToHeaderFields();\n                params.headerFields = filterExcludedKeys(userSelectedFields);\n            }\n            return params;\n        }\n        return params;\n    }\n    /**\n     * Main function which handles the processing of a record, or document to be converted to CSV format\n     * This function specifies and performs the necessary operations in the necessary order\n     * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n     * * Order of operations:\n     * - Get fields from provided key list (as array of actual values)\n     * - Convert the values to csv/string representation [possible option here for custom converters?]\n     * - Trim fields\n     * - Determine if they need to be wrapped (& wrap if necessary)\n     * - Combine values for each line (by joining by field delimiter)\n     */\n    function processRecords(params) {\n        params.recordString = params.records.map((record) => {\n            // Retrieve data for each of the headerFields from this record\n            const recordFieldData = retrieveRecordFieldData(record, params.headerFields), \n            // Process the data in this record and return the\n            processedRecordData = recordFieldData.map((fieldValue) => {\n                fieldValue = trimRecordFieldValue(fieldValue);\n                fieldValue = preventCsvInjection(fieldValue);\n                let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n                stringified = wrapFieldValueIfNecessary(stringified);\n                return stringified;\n            });\n            // Join the record data by the field delimiter\n            return generateCsvRowFromRecord(processedRecordData);\n        }).join(options.delimiter.eol);\n        return params;\n    }\n    /**\n     * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n     */\n    function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n        const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n        // If we have an array and it's either empty of full of empty values, then use an empty value representation\n        if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n            return options.emptyFieldValue || '';\n        }\n        else if (filteredRecordFieldValue.length === 1) {\n            // Otherwise, we have an array of actual values...\n            // Since we are expanding array objects, we will want to key in on values of objects.\n            return filteredRecordFieldValue[0]; // Extract the single value in the array\n        }\n        return recordFieldValue;\n    }\n    /**\n     * Gets all field values from a particular record for the given list of fields\n     */\n    function retrieveRecordFieldData(record, fields) {\n        const recordValues = [];\n        fields.forEach((field) => {\n            let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n            if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n                recordFieldValue = options.emptyFieldValue;\n            }\n            else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n                recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n            }\n            recordValues.push(recordFieldValue);\n        });\n        return recordValues;\n    }\n    /**\n     * Converts a record field value to its string representation\n     */\n    function recordFieldValueToString(fieldValue) {\n        const isDate = fieldValue instanceof Date; // store to avoid checking twice\n        if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n            return JSON.stringify(fieldValue);\n        }\n        else if (typeof fieldValue === 'undefined') {\n            return 'undefined';\n        }\n        else if (isDate && options.useDateIso8601Format) {\n            return fieldValue.toISOString();\n        }\n        else {\n            return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n        }\n    }\n    /**\n     * Trims the record field value, if specified by the user's provided options\n     */\n    function trimRecordFieldValue(fieldValue) {\n        if (options.trimFieldValues) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(trimRecordFieldValue);\n            }\n            else if (typeof fieldValue === 'string') {\n                return fieldValue.trim();\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Prevent CSV injection on strings if specified by the user's provided options.\n     * Mitigation will be done by ensuring that the first character doesn't being with:\n     * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n     * More info: https://owasp.org/www-community/attacks/CSV_Injection\n     */\n    function preventCsvInjection(fieldValue) {\n        if (options.preventCsvInjection) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(preventCsvInjection);\n            }\n            else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n                return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Escapes quotation marks in the field value, if necessary, and appropriately\n     * wraps the record field value if it contains a comma (field delimiter),\n     * quotation mark (wrap delimiter), or a line break (CRLF)\n     */\n    function wrapFieldValueIfNecessary(fieldValue) {\n        const wrapDelimiter = options.delimiter.wrap;\n        // eg. includes quotation marks (default delimiter)\n        if (fieldValue.includes(options.delimiter.wrap)) {\n            // add an additional quotation mark before each quotation mark appearing in the field value\n            fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n        }\n        // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n        //   then enclose it in quotation marks (wrap delimiter)\n        if (fieldValue.includes(options.delimiter.field) ||\n            fieldValue.includes(options.delimiter.wrap) ||\n            fieldValue.match(crlfSearchRegex) ||\n            options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n            // wrap the field's value in a wrap delimiter (quotation marks by default)\n            fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n        }\n        return fieldValue;\n    }\n    /**\n     * Generates the CSV record string by joining the field values together by the field delimiter\n     */\n    function generateCsvRowFromRecord(recordFieldValues) {\n        return recordFieldValues.join(options.delimiter.field);\n    }\n    /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n    /**\n     * Performs the final CSV construction by combining the fields in the appropriate\n     * order depending on the provided options values and sends the generated CSV\n     * back to the user\n     */\n    function generateCsvFromComponents(params) {\n        const header = params.header, records = params.recordString, \n        // If we are prepending the header, then add an EOL, otherwise just return the records\n        csv = (options.excelBOM ? constants_1.excelBOM : '') +\n            (options.prependHeader ? header + options.delimiter.eol : '') +\n            records;\n        return csv;\n    }\n    /** MAIN CONVERTER FUNCTION **/\n    /**\n     * Internally exported json2csv function\n     */\n    function convert(data) {\n        // Single document, not an array\n        if (!Array.isArray(data)) {\n            data = [data]; // Convert to an array of the given document\n        }\n        // Retrieve the heading and then generate the CSV with the keys that are identified\n        const headerFields = {\n            headerFields: retrieveHeaderFields(data),\n            records: data,\n            header: '',\n            recordString: '',\n        };\n        const unwinded = unwindRecordsIfNecessary(headerFields);\n        const processed = processRecords(unwinded);\n        const wrapped = wrapHeaderFields(processed);\n        const trimmed = trimHeaderFields(wrapped);\n        const generated = generateCsvHeader(trimmed);\n        return generateCsvFromComponents(generated);\n    }\n    return {\n        convert,\n    };\n};\nexports.Json2Csv = Json2Csv;\n"],"mappings":"AAAA,YAAY;;AACZ,IAAIA,eAAe,GAAI,IAAI,IAAI,IAAI,CAACA,eAAe,KAAMC,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EAC5F,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5B,IAAIG,IAAI,GAAGP,MAAM,CAACQ,wBAAwB,CAACL,CAAC,EAAEC,CAAC,CAAC;EAChD,IAAI,CAACG,IAAI,KAAK,KAAK,IAAIA,IAAI,GAAG,CAACJ,CAAC,CAACM,UAAU,GAAGF,IAAI,CAACG,QAAQ,IAAIH,IAAI,CAACI,YAAY,CAAC,EAAE;IACjFJ,IAAI,GAAG;MAAEK,UAAU,EAAE,IAAI;MAAEC,GAAG,EAAE,SAAAA,CAAA,EAAW;QAAE,OAAOV,CAAC,CAACC,CAAC,CAAC;MAAE;IAAE,CAAC;EAC/D;EACAJ,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAEG,EAAE,EAAEE,IAAI,CAAC;AACtC,CAAC,GAAK,UAASL,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EACxB,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5BF,CAAC,CAACG,EAAE,CAAC,GAAGF,CAAC,CAACC,CAAC,CAAC;AAChB,CAAE,CAAC;AACH,IAAIW,kBAAkB,GAAI,IAAI,IAAI,IAAI,CAACA,kBAAkB,KAAMf,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEc,CAAC,EAAE;EAC3FhB,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAE,SAAS,EAAE;IAAEU,UAAU,EAAE,IAAI;IAAEK,KAAK,EAAED;EAAE,CAAC,CAAC;AACvE,CAAC,GAAI,UAASd,CAAC,EAAEc,CAAC,EAAE;EAChBd,CAAC,CAAC,SAAS,CAAC,GAAGc,CAAC;AACpB,CAAC,CAAC;AACF,IAAIE,YAAY,GAAI,IAAI,IAAI,IAAI,CAACA,YAAY,IAAK,UAAUC,GAAG,EAAE;EAC7D,IAAIA,GAAG,IAAIA,GAAG,CAACV,UAAU,EAAE,OAAOU,GAAG;EACrC,IAAIC,MAAM,GAAG,CAAC,CAAC;EACf,IAAID,GAAG,IAAI,IAAI,EAAE,KAAK,IAAIf,CAAC,IAAIe,GAAG,EAAE,IAAIf,CAAC,KAAK,SAAS,IAAIJ,MAAM,CAACqB,SAAS,CAACC,cAAc,CAACC,IAAI,CAACJ,GAAG,EAAEf,CAAC,CAAC,EAAEL,eAAe,CAACqB,MAAM,EAAED,GAAG,EAAEf,CAAC,CAAC;EACxIW,kBAAkB,CAACK,MAAM,EAAED,GAAG,CAAC;EAC/B,OAAOC,MAAM;AACjB,CAAC;AACDpB,MAAM,CAACc,cAAc,CAACU,OAAO,EAAE,YAAY,EAAE;EAAEP,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DO,OAAO,CAACC,QAAQ,GAAG,KAAK,CAAC;AACzB,MAAMC,UAAU,GAAGC,OAAO,CAAC,UAAU,CAAC;AACtC,MAAMC,OAAO,GAAGD,OAAO,CAAC,OAAO,CAAC;AAChC,MAAME,WAAW,GAAGF,OAAO,CAAC,aAAa,CAAC;AAC1C,MAAMG,KAAK,GAAGZ,YAAY,CAACS,OAAO,CAAC,SAAS,CAAC,CAAC;AAC9C,MAAMF,QAAQ,GAAG,SAAAA,CAAUM,OAAO,EAAE;EAChC,MAAMC,uBAAuB,GAAG,IAAIC,MAAM,CAACF,OAAO,CAACG,SAAS,CAACC,IAAI,EAAE,GAAG,CAAC;IAAEC,eAAe,GAAG,UAAU;IAAEC,iBAAiB,GAAGN,OAAO,CAACO,UAAU,IAAI,OAAOP,OAAO,CAACO,UAAU,KAAK,UAAU,GAAGP,OAAO,CAACO,UAAU,GAAG,IAAI;IAAEC,yBAAyB,GAAGR,OAAO,CAACS,kBAAkB,IAAI,CAACT,OAAO,CAACU,YAAY;IAAEC,YAAY,GAAG;MACnTC,kBAAkB,EAAEZ,OAAO,CAACY,kBAAkB;MAC9CC,mBAAmB,EAAEb,OAAO,CAACa,mBAAmB;MAChDJ,kBAAkB,EAAED,yBAAyB;MAC7CM,8BAA8B,EAAEN,yBAAyB;MACzDO,gBAAgB,EAAE;IACtB,CAAC;EACD;EACA;AACJ;AACA;EACI,SAASC,gBAAgBA,CAACC,IAAI,EAAE;IAC5B;IACA,OAAO,CAAC,CAAC,EAAEpB,OAAO,CAACqB,gBAAgB,EAAED,IAAI,EAAEN,YAAY,CAAC;EAC5D;EACA;AACJ;AACA;AACA;AACA;EACI,SAASQ,cAAcA,CAACC,eAAe,EAAE;IACrC;IACA,IAAIA,eAAe,CAACC,MAAM,KAAK,CAAC,EAAE;MAC9B,OAAO,EAAE;IACb;IACA;IACA,IAAIrB,OAAO,CAACsB,sBAAsB,EAAE;MAChC,OAAOA,sBAAsB,CAACF,eAAe,CAAC;IAClD,CAAC,MACI;MACD;MACA,MAAMG,gBAAgB,GAAGxB,KAAK,CAACyB,MAAM,CAACzB,KAAK,CAAC0B,OAAO,CAACL,eAAe,CAAC,CAAC;MACrE,OAAOG,gBAAgB;IAC3B;EACJ;EACA;AACJ;AACA;AACA;AACA;EACI,SAASD,sBAAsBA,CAACF,eAAe,EAAE;IAC7C;IACA,MAAMM,cAAc,GAAGN,eAAe,CAAC,CAAC,CAAC;MAAEO,qBAAqB,GAAGP,eAAe,CAACQ,KAAK,CAAC,CAAC,CAAC;MAAEC,iBAAiB,GAAGC,gCAAgC,CAACJ,cAAc,EAAEC,qBAAqB,CAAC;IACxL;IACA,IAAIE,iBAAiB,EAAE;MACnB,MAAM,IAAIE,KAAK,CAACjC,WAAW,CAACkC,MAAM,CAACC,QAAQ,CAACC,aAAa,CAAC;IAC9D;IACA,OAAOR,cAAc;EACzB;EACA;AACJ;AACA;EACI,SAASI,gCAAgCA,CAACJ,cAAc,EAAEC,qBAAqB,EAAE;IAC7E,OAAOA,qBAAqB,CAACQ,MAAM,CAAC,CAACN,iBAAiB,EAAEO,cAAc,KAAK;MACvE;MACA,MAAMC,mBAAmB,GAAGtC,KAAK,CAACuC,wBAAwB,CAACZ,cAAc,EAAEU,cAAc,CAAC,CAACf,MAAM;MACjG,OAAOgB,mBAAmB,GAAG,CAAC,GACxBR,iBAAiB,GAAG,CAAC,GACrBA,iBAAiB;IAC3B,CAAC,EAAE,CAAC,CAAC;EACT;EACA;AACJ;AACA;EACI,SAASU,kBAAkBA,CAACC,QAAQ,EAAE;IAClC,IAAIxC,OAAO,CAACyC,WAAW,EAAE;MACrB,OAAOD,QAAQ,CAACE,MAAM,CAAEC,OAAO,IAAK;QAChC,KAAK,MAAMC,WAAW,IAAI5C,OAAO,CAACyC,WAAW,EAAE;UAC3C;UACA,MAAMI,KAAK,GAAGD,WAAW,YAAY1C,MAAM,GAAG0C,WAAW,GAAG,IAAI1C,MAAM,CAAC,IAAI0C,WAAW,EAAE,CAAC;UACzF,IAAIA,WAAW,KAAKD,OAAO,IAAIA,OAAO,CAACG,KAAK,CAACD,KAAK,CAAC,EAAE;YACjD,OAAO,KAAK,CAAC,CAAC;UAClB;QACJ;QACA,OAAO,IAAI,CAAC,CAAC;MACjB,CAAC,CAAC;IACN;IACA,OAAOL,QAAQ;EACnB;EACA;AACJ;AACA;EACI,SAASO,gBAAgBA,CAACC,UAAU,EAAE;IAClC,IAAIhD,OAAO,CAACiD,UAAU,IAAI,OAAOjD,OAAO,CAACiD,UAAU,KAAK,UAAU,EAAE;MAChE,OAAOD,UAAU,CAACE,IAAI,CAAClD,OAAO,CAACiD,UAAU,CAAC;IAC9C,CAAC,MACI,IAAIjD,OAAO,CAACiD,UAAU,EAAE;MACzB,OAAOD,UAAU,CAACE,IAAI,CAAC,CAAC;IAC5B;IACA,OAAOF,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASG,gBAAgBA,CAACC,MAAM,EAAE;IAC9B,IAAIpD,OAAO,CAACmD,gBAAgB,EAAE;MAC1BC,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAEC,KAAK,IAAKA,KAAK,CAACC,KAAK,CAAC,GAAG,CAAC,CACpEF,GAAG,CAAEG,SAAS,IAAKA,SAAS,CAACC,IAAI,CAAC,CAAC,CAAC,CACpCC,IAAI,CAAC,GAAG,CAAC,CAAC;IACnB;IACA,OAAOP,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASQ,gBAAgBA,CAACR,MAAM,EAAE;IAC9B;IACA,IAAIpD,OAAO,CAAC6D,aAAa,EAAE;MACvBT,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAC,UAAUQ,UAAU,EAAE;QAChE,OAAOC,yBAAyB,CAACD,UAAU,CAAC;MAChD,CAAC,CAAC;IACN;IACA,OAAOV,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASY,iBAAiBA,CAACZ,MAAM,EAAE;IAC/B;IACA,MAAMa,iBAAiB,GAAGhG,MAAM,CAACiG,IAAI,CAAClE,OAAO,CAACmE,aAAa,CAAC;IAC5Df,MAAM,CAACgB,MAAM,GAAGhB,MAAM,CAACC,YAAY,CAC9BC,GAAG,CAAC,UAAUC,KAAK,EAAE;MACtB,IAAIc,SAAS,GAAGd,KAAK;MACrB;MACA,IAAIU,iBAAiB,CAACK,QAAQ,CAACf,KAAK,CAAC,EAAE;QACnCc,SAAS,GAAGrE,OAAO,CAACmE,aAAa,CAACZ,KAAK,CAAC;MAC5C,CAAC,MACI,IAAI,CAACvD,OAAO,CAACuE,sBAAsB,EAAE;QACtC;QACAF,SAAS,GAAGA,SAAS,CAACG,OAAO,CAAC,OAAO,EAAE,GAAG,CAAC;MAC/C;MACA,OAAOH,SAAS;IACpB,CAAC,CAAC,CACGV,IAAI,CAAC3D,OAAO,CAACG,SAAS,CAACoD,KAAK,CAAC;IAClC,OAAOH,MAAM;EACjB;EACA,SAASqB,yBAAyBA,CAAA,EAAG;IACjC,IAAI,CAACzE,OAAO,CAACkE,IAAI,EACb,OAAO,EAAE;IACb,OAAOlE,OAAO,CAACkE,IAAI,CAACZ,GAAG,CAAEoB,GAAG,IAAK;MAC7B,IAAI,OAAOA,GAAG,KAAK,QAAQ,IAAI,OAAO,IAAIA,GAAG,EAAE;QAC3C1E,OAAO,CAACmE,aAAa,CAACO,GAAG,CAACnB,KAAK,CAAC,GAAGmB,GAAG,CAACC,KAAK,IAAID,GAAG,CAACnB,KAAK;QACzD,OAAOmB,GAAG,CAACnB,KAAK;MACpB;MACA,OAAOmB,GAAG;IACd,CAAC,CAAC;EACN;EACA,SAASE,wBAAwBA,CAAA,EAAG;IAChC,IAAI,CAAC5E,OAAO,CAACkE,IAAI,EACb,OAAO,EAAE;IACb,OAAOlE,OAAO,CAACkE,IAAI,CAACW,OAAO,CAACC,IAAI,IAAI;MAChC,IAAI,OAAOA,IAAI,KAAK,QAAQ,EAAE;QAC1B;QACA,OAAO,EAAE;MACb,CAAC,MACI,IAAIA,IAAI,EAAEC,aAAa,EAAE;QAC1B;QACA,OAAOD,IAAI,CAACvB,KAAK;MACrB;MACA;MACA,OAAO,EAAE;IACb,CAAC,CAAC;EACN;EACA;AACJ;AACA;AACA;EACI,SAASyB,oBAAoBA,CAAC/D,IAAI,EAAE;IAChC,MAAMgE,iBAAiB,GAAGL,wBAAwB,CAAC,CAAC;IACpD,MAAMM,UAAU,GAAGT,yBAAyB,CAAC,CAAC;IAC9C,MAAMzB,UAAU,GAAGhC,gBAAgB,CAACC,IAAI,CAAC;IACzC,MAAMkE,SAAS,GAAGhE,cAAc,CAAC6B,UAAU,CAAC;IAC5C,IAAIhD,OAAO,CAACkE,IAAI,EAAE;MACdlE,OAAO,CAACkE,IAAI,GAAGgB,UAAU;MACzB,MAAME,WAAW,GAAGF,UAAU,CAACL,OAAO,CAAEQ,eAAe,IAAK;QACxD;QACA,IAAI,CAACJ,iBAAiB,CAACX,QAAQ,CAACe,eAAe,CAAC,EAAE;UAC9C,OAAOA,eAAe;QAC1B;QACA;QACA,MAAMC,OAAO,GAAG,EAAE;QAClB,MAAMzC,KAAK,GAAG,IAAI3C,MAAM,CAAC,IAAImF,eAAe,EAAE,CAAC;QAC/C,KAAK,MAAME,WAAW,IAAIJ,SAAS,EAAE;UACjC,IAAIE,eAAe,KAAKE,WAAW,IAAIA,WAAW,CAACzC,KAAK,CAACD,KAAK,CAAC,EAAE;YAC7DyC,OAAO,CAACE,IAAI,CAACD,WAAW,CAAC;UAC7B;QACJ;QACA,OAAOD,OAAO;MAClB,CAAC,CAAC;MACF,IAAI,CAACtF,OAAO,CAACU,YAAY,EAAE;QACvB,MAAM+E,QAAQ,GAAGlD,kBAAkB,CAAC6C,WAAW,CAAC;QAChD,OAAOrC,gBAAgB,CAAC0C,QAAQ,CAAC;MACrC;IACJ;IACA,MAAMA,QAAQ,GAAGlD,kBAAkB,CAAC4C,SAAS,CAAC;IAC9C,OAAOpC,gBAAgB,CAAC0C,QAAQ,CAAC;EACrC;EACA;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAASC,wBAAwBA,CAACtC,MAAM,EAAEuC,SAAS,GAAG,KAAK,EAAE;IACzD,IAAI3F,OAAO,CAACU,YAAY,EAAE;MACtB,MAAMkF,qBAAqB,GAAGxC,MAAM,CAACyC,OAAO,CAACxE,MAAM;MACnD;MACA+B,MAAM,CAACC,YAAY,CAACyC,OAAO,CAAEC,WAAW,IAAK;QACzC3C,MAAM,CAACyC,OAAO,GAAG9F,KAAK,CAACiG,MAAM,CAAC5C,MAAM,CAACyC,OAAO,EAAEE,WAAW,CAAC;MAC9D,CAAC,CAAC;MACF,MAAM1C,YAAY,GAAG2B,oBAAoB,CAAC5B,MAAM,CAACyC,OAAO,CAAC;MACzDzC,MAAM,CAACC,YAAY,GAAGA,YAAY;MAClC;MACA,IAAIuC,qBAAqB,KAAKxC,MAAM,CAACyC,OAAO,CAACxE,MAAM,EAAE;QACjD,OAAOqE,wBAAwB,CAACtC,MAAM,CAAC;MAC3C;MACA;MACA;MACA;MACA,IAAI,CAACuC,SAAS,EAAE;QACZ,OAAOD,wBAAwB,CAACtC,MAAM,EAAE,IAAI,CAAC;MACjD;MACA;MACA,IAAIpD,OAAO,CAACkE,IAAI,EAAE;QACd,MAAM+B,kBAAkB,GAAGxB,yBAAyB,CAAC,CAAC;QACtDrB,MAAM,CAACC,YAAY,GAAGd,kBAAkB,CAAC0D,kBAAkB,CAAC;MAChE;MACA,OAAO7C,MAAM;IACjB;IACA,OAAOA,MAAM;EACjB;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAAS8C,cAAcA,CAAC9C,MAAM,EAAE;IAC5BA,MAAM,CAAC+C,YAAY,GAAG/C,MAAM,CAACyC,OAAO,CAACvC,GAAG,CAAE8C,MAAM,IAAK;MACjD;MACA,MAAMC,eAAe,GAAGC,uBAAuB,CAACF,MAAM,EAAEhD,MAAM,CAACC,YAAY,CAAC;QAC5E;QACAkD,mBAAmB,GAAGF,eAAe,CAAC/C,GAAG,CAAEkD,UAAU,IAAK;UACtDA,UAAU,GAAGC,oBAAoB,CAACD,UAAU,CAAC;UAC7CA,UAAU,GAAGE,mBAAmB,CAACF,UAAU,CAAC;UAC5C,IAAIG,WAAW,GAAGrG,iBAAiB,GAAGA,iBAAiB,CAACkG,UAAU,EAAEI,wBAAwB,CAAC,GAAGA,wBAAwB,CAACJ,UAAU,CAAC;UACpIG,WAAW,GAAG5C,yBAAyB,CAAC4C,WAAW,CAAC;UACpD,OAAOA,WAAW;QACtB,CAAC,CAAC;MACF;MACA,OAAOE,wBAAwB,CAACN,mBAAmB,CAAC;IACxD,CAAC,CAAC,CAAC5C,IAAI,CAAC3D,OAAO,CAACG,SAAS,CAAC2G,GAAG,CAAC;IAC9B,OAAO1D,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAAS2D,4CAA4CA,CAACC,gBAAgB,EAAE;IACpE,MAAMC,wBAAwB,GAAGlH,KAAK,CAACmH,iBAAiB,CAACF,gBAAgB,CAAC;IAC1E;IACA,IAAI,CAACA,gBAAgB,CAAC3F,MAAM,IAAI,CAAC4F,wBAAwB,CAAC5F,MAAM,EAAE;MAC9D,OAAOrB,OAAO,CAACmH,eAAe,IAAI,EAAE;IACxC,CAAC,MACI,IAAIF,wBAAwB,CAAC5F,MAAM,KAAK,CAAC,EAAE;MAC5C;MACA;MACA,OAAO4F,wBAAwB,CAAC,CAAC,CAAC,CAAC,CAAC;IACxC;IACA,OAAOD,gBAAgB;EAC3B;EACA;AACJ;AACA;EACI,SAASV,uBAAuBA,CAACF,MAAM,EAAEgB,MAAM,EAAE;IAC7C,MAAMC,YAAY,GAAG,EAAE;IACvBD,MAAM,CAACtB,OAAO,CAAEvC,KAAK,IAAK;MACtB,IAAIyD,gBAAgB,GAAG,CAAC,CAAC,EAAErH,UAAU,CAAC2H,YAAY,EAAElB,MAAM,EAAE7C,KAAK,CAAC;MAClE,IAAI,CAACxD,KAAK,CAACwH,WAAW,CAACvH,OAAO,CAACmH,eAAe,CAAC,IAAIpH,KAAK,CAACyH,YAAY,CAACR,gBAAgB,CAAC,EAAE;QACrFA,gBAAgB,GAAGhH,OAAO,CAACmH,eAAe;MAC9C,CAAC,MACI,IAAInH,OAAO,CAACS,kBAAkB,IAAIgH,KAAK,CAACC,OAAO,CAACV,gBAAgB,CAAC,EAAE;QACpEA,gBAAgB,GAAGD,4CAA4C,CAACC,gBAAgB,CAAC;MACrF;MACAK,YAAY,CAAC7B,IAAI,CAACwB,gBAAgB,CAAC;IACvC,CAAC,CAAC;IACF,OAAOK,YAAY;EACvB;EACA;AACJ;AACA;EACI,SAAST,wBAAwBA,CAACJ,UAAU,EAAE;IAC1C,MAAMmB,MAAM,GAAGnB,UAAU,YAAYoB,IAAI,CAAC,CAAC;IAC3C,IAAIpB,UAAU,KAAK,IAAI,IAAIiB,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,IAAI,OAAOA,UAAU,KAAK,QAAQ,IAAI,CAACmB,MAAM,EAAE;MAC/F,OAAOE,IAAI,CAACC,SAAS,CAACtB,UAAU,CAAC;IACrC,CAAC,MACI,IAAI,OAAOA,UAAU,KAAK,WAAW,EAAE;MACxC,OAAO,WAAW;IACtB,CAAC,MACI,IAAImB,MAAM,IAAI3H,OAAO,CAAC+H,oBAAoB,EAAE;MAC7C,OAAOvB,UAAU,CAACwB,WAAW,CAAC,CAAC;IACnC,CAAC,MACI;MACD,OAAO,CAAChI,OAAO,CAACiI,eAAe,GAAGzB,UAAU,CAAC0B,QAAQ,CAAC,CAAC,GAAG1B,UAAU,CAAC2B,cAAc,CAAC,CAAC;IACzF;EACJ;EACA;AACJ;AACA;EACI,SAAS1B,oBAAoBA,CAACD,UAAU,EAAE;IACtC,IAAIxG,OAAO,CAACoI,eAAe,EAAE;MACzB,IAAIX,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAAClD,GAAG,CAACmD,oBAAoB,CAAC;MAC/C,CAAC,MACI,IAAI,OAAOD,UAAU,KAAK,QAAQ,EAAE;QACrC,OAAOA,UAAU,CAAC9C,IAAI,CAAC,CAAC;MAC5B;MACA,OAAO8C,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,SAASE,mBAAmBA,CAACF,UAAU,EAAE;IACrC,IAAIxG,OAAO,CAAC0G,mBAAmB,EAAE;MAC7B,IAAIe,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAAClD,GAAG,CAACoD,mBAAmB,CAAC;MAC9C,CAAC,MACI,IAAI,OAAOF,UAAU,KAAK,QAAQ,IAAI,CAACzG,KAAK,CAACsI,QAAQ,CAAC7B,UAAU,CAAC,EAAE;QACpE,OAAOA,UAAU,CAAChC,OAAO,CAAC,gBAAgB,EAAE,EAAE,CAAC;MACnD;MACA,OAAOgC,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;EACI,SAASzC,yBAAyBA,CAACyC,UAAU,EAAE;IAC3C,MAAM8B,aAAa,GAAGtI,OAAO,CAACG,SAAS,CAACC,IAAI;IAC5C;IACA,IAAIoG,UAAU,CAAClC,QAAQ,CAACtE,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,EAAE;MAC7C;MACAoG,UAAU,GAAGA,UAAU,CAAChC,OAAO,CAACvE,uBAAuB,EAAEqI,aAAa,GAAGA,aAAa,CAAC;IAC3F;IACA;IACA;IACA,IAAI9B,UAAU,CAAClC,QAAQ,CAACtE,OAAO,CAACG,SAAS,CAACoD,KAAK,CAAC,IAC5CiD,UAAU,CAAClC,QAAQ,CAACtE,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,IAC3CoG,UAAU,CAAC1D,KAAK,CAACzC,eAAe,CAAC,IACjCL,OAAO,CAACuI,YAAY,KAAK/B,UAAU,KAAK,MAAM,IAAIA,UAAU,KAAK,OAAO,CAAC,EAAE;MAC3E;MACAA,UAAU,GAAG8B,aAAa,GAAG9B,UAAU,GAAG8B,aAAa;IAC3D;IACA,OAAO9B,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASK,wBAAwBA,CAAC2B,iBAAiB,EAAE;IACjD,OAAOA,iBAAiB,CAAC7E,IAAI,CAAC3D,OAAO,CAACG,SAAS,CAACoD,KAAK,CAAC;EAC1D;EACA;EACA;AACJ;AACA;AACA;AACA;EACI,SAASkF,yBAAyBA,CAACrF,MAAM,EAAE;IACvC,MAAMgB,MAAM,GAAGhB,MAAM,CAACgB,MAAM;MAAEyB,OAAO,GAAGzC,MAAM,CAAC+C,YAAY;MAC3D;MACAuC,GAAG,GAAG,CAAC1I,OAAO,CAAC2I,QAAQ,GAAG7I,WAAW,CAAC6I,QAAQ,GAAG,EAAE,KAC9C3I,OAAO,CAAC6D,aAAa,GAAGO,MAAM,GAAGpE,OAAO,CAACG,SAAS,CAAC2G,GAAG,GAAG,EAAE,CAAC,GAC7DjB,OAAO;IACX,OAAO6C,GAAG;EACd;EACA;EACA;AACJ;AACA;EACI,SAASE,OAAOA,CAAC3H,IAAI,EAAE;IACnB;IACA,IAAI,CAACwG,KAAK,CAACC,OAAO,CAACzG,IAAI,CAAC,EAAE;MACtBA,IAAI,GAAG,CAACA,IAAI,CAAC,CAAC,CAAC;IACnB;IACA;IACA,MAAMoC,YAAY,GAAG;MACjBA,YAAY,EAAE2B,oBAAoB,CAAC/D,IAAI,CAAC;MACxC4E,OAAO,EAAE5E,IAAI;MACbmD,MAAM,EAAE,EAAE;MACV+B,YAAY,EAAE;IAClB,CAAC;IACD,MAAM0C,QAAQ,GAAGnD,wBAAwB,CAACrC,YAAY,CAAC;IACvD,MAAM8B,SAAS,GAAGe,cAAc,CAAC2C,QAAQ,CAAC;IAC1C,MAAMC,OAAO,GAAGlF,gBAAgB,CAACuB,SAAS,CAAC;IAC3C,MAAM4D,OAAO,GAAG5F,gBAAgB,CAAC2F,OAAO,CAAC;IACzC,MAAME,SAAS,GAAGhF,iBAAiB,CAAC+E,OAAO,CAAC;IAC5C,OAAON,yBAAyB,CAACO,SAAS,CAAC;EAC/C;EACA,OAAO;IACHJ;EACJ,CAAC;AACL,CAAC;AACDnJ,OAAO,CAACC,QAAQ,GAAGA,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}